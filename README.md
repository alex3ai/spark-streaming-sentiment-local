# âš¡ Real-Time Sentiment Analysis Pipeline

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg?style=for-the-badge&logo=python&logoColor=white)
![Apache Spark](https://img.shields.io/badge/Apache_Spark-3.5.0-orange.svg?style=for-the-badge&logo=apachespark&logoColor=white)
![Apache Kafka](https://img.shields.io/badge/Apache_Kafka-3.7.0_(KRaft)-black.svg?style=for-the-badge&logo=apachekafka&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-FinOps_Optimized-2496ED.svg?style=for-the-badge&logo=docker&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green.svg?style=for-the-badge)

> **Uma arquitetura de Engenharia de Dados orientada a eventos, focada em eficiÃªncia de recursos (FinOps), escalabilidade e processamento distribuÃ­do em tempo real.**

---

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [Destaques TÃ©cnicos](#-destaques-tÃ©cnicos)
- [Como Executar](#-como-executar)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [DecisÃµes de Arquitetura](#-decisÃµes-de-arquitetura-adr)
- [Desenvolvimento & Qualidade](#-desenvolvimento--qualidade)
- [Screenshots](#-screenshots)
- [LicenÃ§a](#-licenÃ§a)

---

## ğŸ¯ VisÃ£o Geral

Este projeto implementa um **pipeline de streaming de dados end-to-end** para anÃ¡lise de sentimentos em tempo real, utilizando tecnologias enterprise-grade com foco em **economia de recursos** (FinOps) e **escalabilidade horizontal**.

### CaracterÃ­sticas Principais

- ğŸš€ **Processamento em Tempo Real**: AnÃ¡lise de sentimentos com latÃªncia sub-segundo utilizando Spark Structured Streaming
- ğŸ’° **FinOps Otimizado**: ReduÃ§Ã£o de ~40% no consumo de memÃ³ria atravÃ©s do Kafka KRaft (sem Zookeeper)
- ğŸ”„ **Event-Driven Architecture**: Desacoplamento total entre produtores e consumidores via Apache Kafka
- ğŸ“Š **Escalabilidade Horizontal**: Cluster Spark Standalone com gestÃ£o rigorosa de recursos
- ğŸ›¡ï¸ **ProduÃ§Ã£o-Ready**: Limites de CPU/RAM definidos, checkpointing automÃ¡tico e fault tolerance

---

## ğŸ— Arquitetura

O projeto segue o padrÃ£o **Lambda Architecture** simplificado, implementando um pipeline completo de streaming:
```mermaid
graph LR
    A[ğŸ“± ProducerFake Tweets] -->|JSON Stream| B(Apache KafkaKRaft Mode)
    
    subgraph Docker["ğŸ³ Docker Infrastructure"]
        B -->|Topic: raw-tweets| C{Spark Master7077}
        C -->|Distribute Jobs| D[Spark Worker512MB RAM]
        D -->|NLTK VADERAnalysis| D
        D -->|Enriched Data| B
    end
    
    B -->|Topic: processed-sentiment| E[ğŸ“Š ConsumerDashboard]
    
    classDef producer fill:#4FC3F7,stroke:#0288D1,stroke-width:3px,color:#000
    classDef kafka fill:#FFD54F,stroke:#F57C00,stroke-width:3px,color:#000
    classDef spark fill:#FF8A65,stroke:#D84315,stroke-width:3px,color:#000
    classDef consumer fill:#81C784,stroke:#388E3C,stroke-width:3px,color:#000
    
    class A producer
    class B kafka
    class C,D spark
    class E consumer
    
    style Docker fill:#263238,stroke:#607D8B,stroke-width:2px,color:#fff
```

### Fluxo de Dados

1. **IngestÃ£o**: Producer simula tweets usando Faker e envia para o tÃ³pico `raw-tweets`
2. **Processamento**: Spark Streaming consome mensagens, aplica anÃ¡lise de sentimento (NLTK VADER) via Pandas UDF
3. **Enriquecimento**: Adiciona score de sentimento (-1.0 a +1.0) e publica no tÃ³pico `processed-sentiment`
4. **Consumo**: Consumer lÃª dados enriquecidos e exibe em tempo real com formataÃ§Ã£o visual

---

## âœ¨ Destaques TÃ©cnicos

### 1. **Kafka sem Zookeeper (KRaft Mode)**
- **Impacto**: ReduÃ§Ã£o de ~512MB de RAM e eliminaÃ§Ã£o de um ponto de falha
- **BenefÃ­cio**: SimplificaÃ§Ã£o da arquitetura e reduÃ§Ã£o de custos operacionais em cloud

### 2. **Spark Standalone Cluster com GestÃ£o de Recursos**
- Limites explÃ­citos via `deploy.resources.limits` (CPU: 1 core, RAM: 1.5GB)
- Arquitetura desacoplada Master/Worker para escalabilidade futura
- ConfiguraÃ§Ã£o de memÃ³ria otimizada (`SPARK_DAEMON_MEMORY=512m`)

### 3. **Pandas UDF (Vectorized Processing)**
- Utiliza **Apache Arrow** para transferÃªncia zero-copy entre Spark e Pandas
- **Performance**: 3-100x mais rÃ¡pido que UDFs tradicionais para operaÃ§Ãµes de ML/NLP
- Evita overhead de serializaÃ§Ã£o Python â†” JVM

### 4. **ResiliÃªncia e Compatibilidade Multi-Ambiente**
- DetecÃ§Ã£o automÃ¡tica de ambiente (Docker vs Local) via `/.dockerenv`
- API Version explÃ­cita (`api_version=(2,8,1)`) para estabilidade em Windows/WSL
- Failsafe NLTK: Download automÃ¡tico de lÃ©xicos se nÃ£o encontrados

### 5. **Checkpoint Strategy**
- LocalizaÃ§Ã£o persistente: `/data/checkpoints/sentiment_job_v1`
- Garante **exactly-once semantics** e recuperaÃ§Ã£o automÃ¡tica de falhas

---

## ğŸš€ Como Executar

### PrÃ©-requisitos

- **Docker** (v20.10+) & **Docker Compose** (v2.0+)
- **Python** 3.10+ (para scripts locais)
- **Make** (opcional, mas recomendado)
- **4GB RAM** disponÃ­vel (2GB para Spark + 768MB para Kafka)

---

### 1ï¸âƒ£ InicializaÃ§Ã£o do Ambiente

Clone o repositÃ³rio e suba a infraestrutura completa:
```bash
# Clone o repositÃ³rio
git clone https://github.com/Alefx33/spark-streaming-sentiment-local.git
cd spark-streaming-sentiment-local

# Suba Kafka + Spark Cluster (build automÃ¡tico)
make up

# OU, se nÃ£o tiver Make instalado:
docker-compose up -d --build
```

â³ **Aguarde ~30-45 segundos** para que os serviÃ§os inicializem completamente.

---

### 2ï¸âƒ£ VerificaÃ§Ã£o de SaÃºde do Cluster

Antes de executar os jobs, confirme que o cluster estÃ¡ operacional:

| ServiÃ§o | URL | DescriÃ§Ã£o |
|---------|-----|-----------|
| **Spark Master UI** | [http://localhost:9090](http://localhost:9090) | Dashboard do cluster (workers, jobs ativos) |
| **Kafka Broker** | `localhost:9094` | Porta externa para produtores/consumidores locais |

âœ… **Checkpoint**: VocÃª deve ver **1 Worker ativo** na Spark UI.

---

### 3ï¸âƒ£ Executando o Pipeline Completo

Abra **3 terminais separados** para visualizar o fluxo end-to-end:

#### ğŸŸ¢ Terminal A: Producer (Gerador de Dados)
```bash
python -m app.scripts.producer
```

**O que faz**: Simula um stream contÃ­nuo de tweets (5-20 palavras, usuÃ¡rios aleatÃ³rios) e envia para `raw-tweets`.

**SaÃ­da esperada**:
```
âœ… Conectado ao Kafka em 127.0.0.1:9094
ğŸš€ Iniciando stream de tweets para: 'raw-tweets'
ğŸ“¤ Tweet enviado de @john_doe
ğŸ“¤ Tweet enviado de @alice_smith
```

---

#### ğŸŸ¡ Terminal B: Spark Job (Processamento)
```bash
docker exec -it spark-master /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
  --executor-memory 512m \
  /app/jobs/sentiment.py
```

**O que faz**: Submete o job de anÃ¡lise de sentimento ao cluster. O Spark consome `raw-tweets`, aplica NLTK VADER e publica no tÃ³pico `processed-sentiment`.

**Logs importantes**:
```
INFO SparkContext: Running Spark version 3.5.0
INFO DAGScheduler: Job 0 finished
```

---

#### ğŸ”µ Terminal C: Consumer (VisualizaÃ§Ã£o)
```bash
python -m app.scripts.consumer
```

**O que faz**: LÃª os dados enriquecidos e exibe com formataÃ§Ã£o colorida baseada no score de sentimento.

**SaÃ­da esperada**:

![Consumer Output](https://github.com/alex3ai/spark-streaming-sentiment-local/blob/main/img/consumer_printer.png)


---

#### ğŸ¬ DemonstraÃ§Ã£o Visual

![Producer in Action](https://github.com/alex3ai/spark-streaming-sentiment-local/blob/main/img/producer.png)

*Producer gerando tweets sintÃ©ticos em tempo real*

---

### 4ï¸âƒ£ Monitoramento AvanÃ§ado
```bash
# Acompanhar logs de todos os serviÃ§os
make logs

# Verificar status dos containers
docker-compose ps

# Acessar shell do Spark Master
docker exec -it spark-master /bin/bash
```

---

### 5ï¸âƒ£ Parar o Ambiente
```bash
# Parar todos os serviÃ§os
make down

# OU
docker-compose down

# Para limpar volumes persistentes (CUIDADO: apaga dados do Kafka)
docker-compose down -v
```

---

## ğŸ“‚ Estrutura do Projeto
```plaintext
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # ConfiguraÃ§Ã£o centralizada (env-aware)
â”‚   â”œâ”€â”€ jobs/
â”‚   â”‚   â””â”€â”€ sentiment.py       # Spark Structured Streaming Job
â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â””â”€â”€ tweet.py           # Schema StructType para validaÃ§Ã£o
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ producer.py        # Simulador de tweets (Faker)
â”‚       â””â”€â”€ consumer.py        # Leitor do tÃ³pico processado
â”‚
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ Dockerfile             # Imagem otimizada (Python 3.10 + Spark 3.5.0)
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ adr/
â”‚   â”‚   â””â”€â”€ 001-uso-do-kafka.md # ADR: Kafka KRaft vs Zookeeper
â”‚   â””â”€â”€ ENGINEERING_GUIDE.md    # PrincÃ­pios e padrÃµes do projeto
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/                  # Testes unitÃ¡rios (pytest)
â”‚   â””â”€â”€ integration/           # Testes de integraÃ§Ã£o
â”‚
â”œâ”€â”€ docker-compose.yml         # OrquestraÃ§Ã£o (Kafka + Spark cluster)
â”œâ”€â”€ Makefile                   # AutomaÃ§Ã£o de comandos
â”œâ”€â”€ pyproject.toml             # Gerenciamento de dependÃªncias
â”œâ”€â”€ .pre-commit-config.yaml    # Hooks de qualidade (Black, Flake8)
â””â”€â”€ README.md                  # Este arquivo
```

### Arquivos-Chave

| Arquivo | Responsabilidade |
|---------|------------------|
| `app/config.py` | DetecÃ§Ã£o de ambiente (Docker vs Local) e configuraÃ§Ã£o de endpoints |
| `app/jobs/sentiment.py` | LÃ³gica principal do Spark Streaming + Pandas UDF |
| `infra/Dockerfile` | Build otimizado com Java 17, Spark 3.5.0 e NLTK prÃ©-configurado |
| `docker-compose.yml` | Define limites de recursos (`deploy.resources.limits`) |

---

## ğŸ§  DecisÃµes de Arquitetura (ADR)

Documentamos escolhas tÃ©cnicas crÃ­ticas seguindo o padrÃ£o **MADR** (Markdown Architectural Decision Records):

### [ADR-001: AdoÃ§Ã£o do Kafka em Modo KRaft](docs/adr/001-uso-do-kafka.md)

**Contexto**: Necessidade de mensageria para streaming com replayability (vital para MLOps).

**DecisÃ£o**: Kafka 3.7.0 em modo KRaft (sem Zookeeper).

**ConsequÃªncias**:
- âœ… ReduÃ§Ã£o de ~40% no consumo de memÃ³ria
- âœ… SimplificaÃ§Ã£o da arquitetura (1 serviÃ§o a menos)
- âš ï¸ Curva de aprendizado maior que RabbitMQ

**Alternativas Rejeitadas**:
- RabbitMQ (retenÃ§Ã£o de logs limitada)
- Google Pub/Sub (vendor lock-in)

---

## ğŸ›  Desenvolvimento & Qualidade

### Pre-Commit Hooks

O projeto utiliza **automaÃ§Ã£o de qualidade** para prevenir erros antes do commit:
```bash
# Instalar hooks (executa Black, Flake8, trailing-whitespace)
make setup

# OU manualmente:
pip install pre-commit
pre-commit install
```

**Ferramentas ativas**:
- **Black**: FormataÃ§Ã£o automÃ¡tica (line-length: 120)
- **Flake8**: Linting (PEP8 compliance)
- **Pre-commit hooks**: Trailing whitespace, end-of-file fixer

---

### ConvenÃ§Ãµes de CÃ³digo

1. **Imports Absolutos**: Sempre use `from app.config import settings` (nunca relativos)
2. **Type Hints**: ObrigatÃ³rios em funÃ§Ãµes pÃºblicas
3. **Docstrings**: Siga o padrÃ£o Google para funÃ§Ãµes complexas
4. **Commits**: Conventional Commits (`feat:`, `fix:`, `infra:`, `docs:`)

Exemplo:
```bash
git commit -m "feat(spark): add pandas udf for sentiment analysis"
git commit -m "infra(docker): reduce kafka memory limit to 768MB"
```

---

### Testes (Roadmap)
```bash
# Executar testes unitÃ¡rios
make test

# OU dentro do container:
docker exec -it spark-master pytest /app/tests
```

**Cobertura atual**: ğŸš§ Em desenvolvimento

---

## ğŸ“¸ Screenshots

### Producer Gerando Tweets
![Producer](https://github.com/alex3ai/spark-streaming-sentiment-local/blob/main/img/producer.png)

### Consumer Exibindo AnÃ¡lise de Sentimentos
![Consumer](https://github.com/alex3ai/spark-streaming-sentiment-local/blob/main/img/consumer_printer.png)

---

## ğŸ“Š MÃ©tricas de Performance

| MÃ©trica | Valor | ObservaÃ§Ã£o |
|---------|-------|------------|
| **LatÃªncia (E2E)** | < 500ms | Producer â†’ Kafka â†’ Spark â†’ Consumer |
| **Throughput** | ~200 msgs/seg | ConfiguraÃ§Ã£o local (1 worker) |
| **MemÃ³ria Total** | ~2.3GB | Kafka (768MB) + Spark (1.5GB) |
| **CPU UtilizaÃ§Ã£o** | 30-50% | 2 cores alocados (1 por serviÃ§o) |

*MediÃ§Ãµes realizadas em ambiente local (Windows 11 WSL2, 16GB RAM)*

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para mudanÃ§as significativas:

1. Abra uma **issue** descrevendo a proposta
2. Crie um **fork** do projeto
3. Crie uma **branch** de feature (`git checkout -b feat/amazing-feature`)
4. Commit suas mudanÃ§as (`git commit -m 'feat: add amazing feature'`)
5. Push para a branch (`git push origin feat/amazing-feature`)
6. Abra um **Pull Request**

**Importante**: Todos os PRs devem passar pelos hooks do pre-commit.

---

## ğŸ“œ LicenÃ§a

DistribuÃ­do sob a licenÃ§a **MIT**. Veja [LICENSE](LICENSE) para mais informaÃ§Ãµes.

---

## ğŸ™ Agradecimentos

- [Apache Spark](https://spark.apache.org/) - Engine de processamento distribuÃ­do
- [Apache Kafka](https://kafka.apache.org/) - Plataforma de streaming
- [NLTK](https://www.nltk.org/) - Toolkit de processamento de linguagem natural
- [Faker](https://faker.readthedocs.io/) - GeraÃ§Ã£o de dados sintÃ©ticos

---

## ğŸ“§ Contato

**Alex Oliveira Mendes** - MLE & SRE Engineer

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/alex-mendes-80244b292/)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-black?style=for-the-badge&logo=github)](https://github.com/Alefx33)

---

<div align="center">

**â­ Se este projeto foi Ãºtil, considere dar uma estrela!**

</div>
