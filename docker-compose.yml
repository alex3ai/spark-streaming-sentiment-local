services:
  # --- Apache Kafka Official (KRaft Mode) ---
  kafka:
    image: apache/kafka:3.7.0
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"
    environment:
      # Configurações Oficiais (Sem o prefixo _CFG_ da Bitnami)
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_LISTENERS: PLAINTEXT://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_LOG_RETENTION_HOURS: 168
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 768M

  # --- Spark Master ---
  spark-master:
    build:
      context: .
      dockerfile: infra/Dockerfile
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080"
      - "7077:7077"
    volumes:
      - ./app:/app
      - ./data:/data
    environment:
      - SPARK_DAEMON_MEMORY=512m
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 1G

  # --- Spark Worker ---
  spark-worker:
    build:
      context: .
      dockerfile: infra/Dockerfile
    container_name: spark-worker
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=1
      - SPARK_WORKER_MEMORY=512m
    volumes:
      - ./app:/app
      - ./data:/data
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
